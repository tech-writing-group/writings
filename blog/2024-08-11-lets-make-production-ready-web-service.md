1. 저는 서비스를 책임지고 운영한 경험이 많지 않아요
2. 회사를 다닌 시간도 4년 정도고, 80명이나 되는 제품팀에서 프로젝트의 전체나 부분을 담당해왔기 때문에 서비스의 전체 그림을 제가 그려본적이 별로 없어요
3. 6월 27일에 릴리즈해서 이제 한 달 남짓 된 도큐먼트라는 제품이 백엔드 파트를 온전히 담당한 첫 프로젝트인데 한 달 동안 운영 단계에서 느낀 것들을 기록해두었습니다.
4. 아마 나중에 살을 붙이면 한 편의 글로 정리가 될 텐데 업데이트로는 초안을 쪼개서 업로드
5. 도큐먼트는 잘 크고 있습니다. 릴리즈 후 매주 주요 지표 (액티브 웹사이트, 퍼블리시된 글 수) 15% ~ 20%씩 상승 중.

## 데이터

### 데이터 변경에 흔적 남기기

6. 주요 데이터 변경에 대해 로그(audit log)를 남기는 것은 아주 중요함

- 사용자 문의가 들어왔을 때 쓰는 시간을 1/10으로 줄여줌
- 가끔 사용자는 실수로 (혹은 고의로) 데이터를 변경하거나 삭제하고 문의를 하곤 함
  - B2B 도메인에 있기 때문에 한 고객(고객사)은 사실 여러 명의 사람이고, 서로 커뮤니케이션이 안 되어서 문의가 들어오는 경우가 있음
  - 드물지만 고객사에 사보타지 하는 빌런이 있기도.. (퇴사 전에 데이터를 삭제한다던가)
- 사용자가 의도한 변경이었는지, 비즈니스 로직의 결함인지 판단하는 데에도 중요한 근거가 됨
- 디버깅할 때 주변 맥락을 재현할 수 있는 정보를 제공해줌
- 사용자는 자신이 처한 문제상황을 잘 설명하지 못함. 알아서 찰떡같이 알아들으려면 맥락을 재구성해낼 수 있어야 함

7. audit log에 들어가는 정보

- 주의: audit log는 데이터 접근 레이어가 아니라 비즈니스 로직 레이어에서 기록하는 것임
- 어떤 엔티티에 추가/변경/삭제가 일어났는가
- 어떤 주체가 행동했는가 (사용자에 의한 변경 외에도 시스템이나 Admin에 의한 변경도 항상 로깅해야 한다.)
- 언제 write가 일어났는가
  - audit log 뿐만 아니라, 모든 데이터베이스 테이블에는 비즈니스 로직에 필요해보이지 않더라도 항상 생성/수정 timestamp가 들어가도록 구성함
  - 때로 수정이 일어날 때마다 +1 되는 버전 컬럼을 운용할 때도 있음
- 기타 정보
  - 비즈니스 로직 procedure 호출 시의 주요 인자
  - before/after
    - 로그는 있는데 로그에 충분한 정보가 없어서 쓸모가 없으면 열받음

8. 로그 남기는 전술

- AOP스러운 접근으로
  - Java를 사용하면 더 간결하고 마법적으로(?) 풀어낼 수 있었을텐데 (하지만 메인 서버도 딱히 이렇게 하고 있진 않음)
- 도큐먼트 서버는 Go를 사용하고 있기 때문에 프록시 패턴(사실 이런 패턴을 뭐라 부르는지 모르겠다)으로 AOP를 구현하고 있음
  (예시 코드는 나중에 글을 쓸때 추가해두자)

9. 부수효과

- 사용자 행동 추적하는 효과가 있음
- 활용 사례
  - KPI 추출
  - 기능 릴리즈 이후 활성도 점검

### 읽기 전용 데이터베이스와 쿼리 시각화 도구

10. 일단 개발자가 직접 운영 DB에 접속해서 쿼리를 날리는 게 일반적인 습관으로 자리잡는 것은 아주 나쁜 생각임

- https://techblog.woowahan.com/2645/ 를 읽어보길 바람
- 안전한 데이터 조회를 위해 read replica를 운용하고 있음

11. 이것에 더해 쿼리 시각화 도구 (Redash) 를 사용하고 있음

- 개발자들이 redash에서 쿼리를 날려보면서 개발과 디버깅을 하는 것이 일상적
- 주의: Redash에서 수십 분 걸리는 쿼리를 실행하는 것은 위험

  - PostgreSQL에서 read replica의 트랜잭션도 master의 vacuum이 작업 실행을 막기 떄문
  - Vacuum이 수십 분 이상 돌지 않을 경우 write가 많은 테이블에서 성능 문제가 생기기 시작함

12. Redash는 시각화 기능도 가지고 있지만, 굳이 기능을 사용하지 않더라도 충분히 유용함

- SAML을 연결할 수 있고
- 자주 사용하는 쿼리를 저장해두거나
- 데이터 export 기능을 편리하게 이용하고 있음

13. 쿼리 시각화 (대시보드)

- SQL을 몰라서 직접 쿼리를 짤 수 없는 팀 멤버도 주요 지표를 확인할 수 있음
- 서비스 초기부터 핵심 지표를 정해두고 Redash에 대시보드로 만들어둠 -> 매주 리포트를 공유 (리포트 쓰는데 15분밖에 안 걸림)

Redash는 백오피스 툴 중에서 가장 팀에서 일상적으로 사용하고 있는 듯.

14. 물론 (백엔드팀 Admin Cell과 웹 클라이언트 팀에서 개발한) "진짜" 백오피스도 있음

- 아직 우리 팀에서 운영하는 기능과 연결이 안되어있음
- 효과: CX팀에서 직접 고객 문의와 관련된 맥락을 파악 못하고 개발자에게 하나하나 문의해야 함 -> 개발자 한 명이 하루에 30분씩 시간 쓰는 요인
- 백오피스에서 개발자가 아닌 사람이 엔티티를 읽고 검색할 수 있으면 나는 하루에 30분씩 획득

### 백업

15. 다행히 고객 데이터를 날려먹은 적은 없음
16. 개발 환경에서 데이터베이스를 통쨰로 날려먹은 적은 있음 (개발자 업적 달성 축하드립니다. :tada:)

- 스테이징 환경에 붙어서 통합테스트를 실행하며 데이터베이스 테이블이 truncate 된게 원인이었음
- 한 번 경험한 다음에 재발 안하도록 방지해 둠 (역시 맞아가며 배워야 함)

17. 당시에 복구는 Amazon RDS의 PITR 기능을 활용하여 할 수 있었음

- PITR 로부터 새 인스턴스 실행 -> pg_dump -> 원래 데이터베이스에 부어주기
- 스테이징 데이터베이스는 하루에 한 번 백업하기 때문에 12시간 어치 데이터를 날려먹긴 함..
- 운영 환경에서는 위에 쓴 방법으로 복구 못할텐데
- 이것도 맞아가면서 배워야 할 테니 (?) 장애 대응훈련을 해보는 것이 좋겠다

## Admin

18. 개발자의 업무 시간을 잡아먹는 것은 Administration

- 토이프로젝트만 해 본 뉴비에게 실제 서비스 운영 경험을 꼭 추천하는 이유입니다.

- 많은 서비스에서 코어 비즈니스 로직은 "사실" 그렇게 까다로운 부분은 아닙니다.

  - 제일 중요하기 때문에 제일 잘 만들어두는 부분

  - 가장 좋은 구조로 설계해두고 깔끔

  - 정작 시간에 쫓겨 정밀하지 못한 코드나, 우아하지 못한 구조로 추가하게 되는 부분은 긴급한 버그 픽스나 admin 작업

- 버그로부터 생긴 데이터 부정합 고치기, 고객 요청에 따른 데이터 확인 또는 수정, 신규 기능 추가에 따른 마이그레이션이 개발자의 시간을 잡아먹습니다.

  - 우리 팀의 경우 (B2B SaaS 도메인) 고객 요청이 많고 사용자 문의로 목소리를 직접 듣게 됨

  - 단순 확인 문의부터, 버그가 발생한 상황인지 맥락 확인, 데이터 옮겨주세요, 데이터 부어주세요, 등등

- 중요한 고객의 요청 하나를 해결하는데 일주일 중 3일을 쓰면 안 됨

- 그렇다고 사용자 문의에 귀를 닫게 되면 1차 피드백을 얻을 창구가 사라지고 점점 뇌피셜로 제품을 만듬

- 이 부분을 적은 노력으로 해결해야 내 시간을 절약해서 사용자에게 필요한 기능을 개발하는 데 쓸 수 있습니다.

### Admin API

19. 엔티티에 대한 읽기와 쓰기 API는 항상 만들어둡니다.

- 반복 작업이고 패턴이 있기 때문에, 프레임워크나 code generation을 사용해도 좋을 것 같습니다.

- 이 부분에서 GitHub Copilot에게 많은 도움을 받고 있습니다. 함수 이름만 잘 작성해도 대부분의 코드를 패턴에 맞게 만들어줌

20. 반복적으로 들어오는 요청 해결 위주로

- 운영 데이터베이스에 update 쿼리를 자주 날리고 있다면 그 작업에 대한 admin API가 필요하다는 신호입니다.

- 다시 한번 개발자 머피의 법칙 (https://techblog.woowahan.com/2645/) 글 추천

- Admin API 호출도 사용자 요청과 마찬가지로 audit log가 남아야 합니다.

21. SDK

- 서버사이드에서 Admin API를 만들었으면, 그걸 클라이언트 사이드에서 코드로 호출할 수 있는 SDK도 준비해두는 것이 유용했습니다.

- 클라이언트 사이드 코드도 생성할 수 있는 도구도 많이 있습니다만 (gRPC같은걸 쓴다면 특히) 이런 걸 아직 사용하고 있지는 않습니다.

  역시 GitHub Copilot의 도움을 많이 받고 있음

- 이전 프로젝트에서 복잡한 작업을 셸스크립트로 만들었지만, 셸스크립트에 능숙하지 않아 작업이 턱턱 막히고 비즈니스 로직을 활용하지 못하는 점이 아쉬움이었습니다.

- 스크립트가 메인 프로젝트와 동일한 repository에서 코드와 비즈니스 로직을 공유할 때 다양한 작업을 처리할 수 있구나 생각했습니다. (메인 애플리케이션과 스크립트를 모노레포로 구성)

### 재사용 가능한 스크립트

22. 결과적으로, Admin API와 모노레포 구조를 통해 복잡한 로직을 담은 스크립트를 30분 내에 뚝딱 작성할 수 있게 되었습니다.

- 데이터 스캔하면서 통계값을 뽑기

- 데이터 정합성 맞추는 마이그레이션 스크립트

- 외부 데이터를 import 혹은 export

- Secondary database로의 전체 혹은 부분 데이터 동기화

23. 스크립트 작성하고 돌리며 했던 실수

- 원래 운영 환경에서 로그가 warn 이상 레벨이었는데, 스크립트에서 출력하는 로그는 info레벨이었기 때문에 로그를 못 보고 스크립트가 끝날 때까지 기다렸던 적이 있습니다.

  - 사실 이것 외에도 운영 환경의 "서버"와 "스크립트"는 살짝 configuration이 다르기 때문에 환경을 구분하는 것이 맞는 선택이었음

- 마찬가지로 스크립트에서 발생한 에러가 이슈 추적 도구(sentry와 datadog 등)에 운영 서버와 동등하게 추적되어 혼란을 주었던 문제

- 중간에 에러가 발생했을 때 에러 로그를 출력하긴 했는데 어떤 데이터에서 에러가 발생했는지를 같이 출력 안해서 찾는데 고생

24. 로그

- 스크립트에서 progress 로그를 print하지 않으면, 스크립트를 실행하는 순간..

  - 돌고 있는건지 어딘가에서 막혀있는건지.. 구별이 안됨

- 로그에 정보를 되도록 많이 담아야 잘못 돌았을 때 실수를 커버할 수 있습니다.

- Dry run 옵션

  - 운영환경 데이터에 개발환경과 다른 문제가 있을 수도 있음

  - 단순히 개발환경에서 충분히 많은 케이스를 테스트를 못했을 수도 있고

  - 데이터 정합성 조건이 변했다던가, 미처 마이그레이션 못한 옛날 데이터라던가, 등등

  - Dry run 옵션을 두고 잘 구현하면 안전하게 테스트 할 수 있음

- Documentation과 스크립트 실행 옵션에 대한 설명을 상세히 달아두면, 내가 휴가 갔을 때도 다른 팀원이 돌릴 수 있는 스크립트가 됩니다.

25. 부수효과

- 다양한 스크립트를 보유하고 있어, 팀에서 기능 QA할 때 쉽게 테스트 환경을 세팅할 수 있게 되었습니다.

- 특히 최근에 릴리즈 한 AI 기반 상담 응대 (RAG) 기능에서 잘 써먹음

### Administration: 정리

26. 스노우볼 굴리기

- 반복적인 작업 처리를 위해 Admin API를 만들어둠

  -> 복잡한 요청들을 거절하지 않고 API 요청 몇 개로 해결

  -> 다시 반복되는 요청 패턴을 Admin SDK와 스크립트로 만들어둠

  -> 스크립트가 여러 개 생기니, 스크립트 템플릿도 만들고 스크립트를 작성하고 돌리기가 쉬워짐

- 패턴화와 내 업무 경험 개선의 반복

- 복잡한 문의 해결을 요구하는 엔터프라이즈 레벨 고객 퀘스트도 깰 수 있게 되어 서비스에 락인 시키고, 서비스 지표에도 도움이 됨

- 일주일에 이러한 요청 두세 개 처리하면서 기능 개발 스케줄에도 문제가 없었다! (휴)

## Reliability

27. 6월 27일 릴리즈 이후 3번의 incident가 있었습니다.

- 2번째 incident 이후 사고 리포트를 쓰기 시작함
- 2개는 도큐먼트 서비스 전체 오류 (다 합해서 40분 정도.), 1개는 데이터 정합성 오류 및 내부 데이터 일부 손실

28. 실수를 할 수 있음: '모든' 실수를 개발과 테스트 단계에서 잡고 가려 하면 일정을 맞추는 것이 불가능합니다.

- 그럼에도 불구하고 개발과 테스트 중 바로잡는 것이 가장 저렴하긴 함
- 95%를 99% 완성도로 만드는 것보다 99%를 99.9%로 만드는 것에 드는 비용이 기술적으로 더 비싸니까, 나머지 1% 완성도는 깔끔한 사고 수습을 통해 채워나가자
- 실수를 두려워해서 모든 코드를 팀 리더(a.k.a. 사고났을 때 책임지는 사람)가 리뷰하고, 새로운 기술 도입에 소극적이고, 기능 릴리즈를 늦게 하는 것이 아니라, 실수해도 빠르게 바로잡을 수 있는 환경을 만들자

29. 그럼에도 불구하고 1) 실수 한 것을 최대한 빨리 인지 2) 고객에게 장애 발생을 전파 3) 이유와 복구 상황을 설명 4) 실수를 수습하는 과정 이 깔끔하면 좋겠습니다.

- 40분이나 service outage된 것이 아쉬움
  - 지금 릴리즈 한 지 2달 정도 됐으니 약 99.95% availability (?) 오히려 좋아
- 첫번째 사고는 4분만에 고쳤는데 나머지 하나 전체 장애 때는 인지하는 데 30분 걸림
- 정합성 문제는 겉으로 볼 때 정상적으로 돌아가는 것처럼 보이니 더 찾기 어려웠고, 하루 만에야 뭔가 잘못되었다는 것을 찾음
  - (당연하겠지만) 실수한 걸 빨리 찾을수록 수습이 쉬움
  - 1시간만에 찾았으면 데이터 몇 개 보정할 걸 하루만에 찾아서 몇백 개를 보정하느라 고생

### 사고 리포트

30. 1번 사고

- 사용자의 입력을 충분히 검증하지 않아서 발생한 문제
- 3번째로 추천 글: https://techblog.woowahan.com/2645/ 를 읽어보기 바람
- 서비스 출시 초기라 서버에 적은 리소스가 할당되어 있었는데 (RAM 500MiB짜리 아주 작고 귀여운 서버), 너무 큰 입력을 잘 처리하지 못해 OOM 발생
- 서버 프로세스가 다중화되어 있었지만, 사용자가 너무 큰 입력을 담은 요청을 보내면서 우리 서버를 차례차례 암살 🔪
- 당시에는 1) 서버 리소스를 늘려서 즉시 대응 하고, 이후 수습 과정에서 2) 사용자 입력을 검증하는 한편 3) 이미 데이터베이스에 들어온 너무 큰 데이터들을 정리하는 스크립트를 통해 해결

31. 2번 사고

- 서버 프로세스 자체는 healthy 였음
- 그런데 서버 애플리케이션으로부터 데이터베이스로 가는 요청이 모두 실패
- 프로세스가 healthy니까 healthcheck는 통과해서 알람이 울리지 않음 -\_-
- 30분만에 팀 내부 제보로 인지하고 5분 후에 복구 함
- 추후 조치로 healthcheck에서 애플리케이션이 의존하는 다른 외부 서비스의 health도 체크하도록 해야겠다. (준비 중)

32. 3번 사고

- 코드 상의 실수로 비동기로 이루어지는 작업 일부가 손실되는 문제
- 사용자의 기능 사용에는 영향이 없지만, secondary database로의 동기화가 깨지는 문제점
- 동기화를 Apache Kafka나 Kinesis Data Stream처럼 replay 할 수 있는 시스템이었다면 더 간단했겠지만, 그렇게 하고 있지 않았음
- 문제가 발생했던 구간에서 업데이트가 일어났던 데이터를 찾고, secondary database에 다시 부어넣어주는 스크립트를 통해 해결
- 아직 서비스가 작기 떄문에 영향받은 데이터가 적어서 (수백 개 정도) 수동으로 처리했지만, 나중에는 앞서 언급한것처럼 replay 할 수 있는 시스템이 있어야 할텐데
- 그런데 역시 문제는 언제 이런 것들을 도입하는 것이 적절한가의 문제 (a.k.a. 닭잡칼 🐓 vs 소잡칼 🐄)

### 알람

- ...

### 로그

- ...

## (아직은) 크게 도움이 안 되었던 것들

- Request Trace
  - HTTP req context에 trace id를 발급하고 이를 바탕으로 버그를 추적하려고 프로젝트 초기에 세팅
  - 아직 비즈니스 로직이 간단하고 execution path를 따라가기 어렵지 않음. 그래서 흩어져 있는 로그를 trace id와 함께 보는 경우가 없었음
- Datadog APM과 Trace
  - 같은 이유로 APM도 아직 도움은 안 됨
  - 사실 메인 API 서버에서는 아주 잘 쓰고 있음, 그런데 지금 하고 있는 작은 프로젝트에서는 sentry와 application log로도 충분
    - 메인 API 서버에서 아주 잘 쓰고있는 기능
      - 코드에서 critical section에 따로 trace 달아서 퍼포먼스 모니터링 (HTTP trace로 보이지 않는 queue나 stream을 consuming하는 부분에서 유용)
      - Service dependency map과 서비스별 체류 시간: 장애 발생 시 바로 보는 지표로, 어떤 컴포넌트가 문제인지 즉시 파악할 수 있게 해줌
      - 넓은 시간 범위의 (주~달 단위) 트렌드 파악: 시간이 지날수록 성능이 악화되어 개선이 필요한 기능을 짚어낼 수 있게 해줌 -> 3~4달 후에 잠재적인 장애 예방
  - 비싸긴 한데 돈값은 한다
  - 그런데 작은 프로젝트에서는 글쎄
  - 프로젝트가 더 커지면, 또는 성능 개선할 때 도움이 될 것 같다.
  - 겸사겸사 다른 마이크로서비스로의 요청이나, RDS 쿼리에 대한 trace를 달아두었다.
