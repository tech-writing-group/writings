---
slug: lets-make-production-ready-web-service
title: 채널톡 동사무소
unlisted: true
---

# 채널톡 동사무소

안녕하세요, 채널톡 백엔드 개발자 두기입니다 👋

저는 최근 출시된 [도큐먼트](https://channel.io/ko/documents) 제품을 개발하고 있어요. 직접 서비스를 책임지고 운영하는 것은 이번이 첫 경험이에요. 6월 27일에 공식 릴리즈 된 이후 두 달 정도 지났는데, **운영 단계**의 에피소드와 느낀 점을 정리하는 글입니다. 도큐먼트를 포함한 채널톡이라는 서비스는 다른 기업이 사용하는 B2B 제품이기 때문에 사용자의 요청이나 문의, 클레임이 B2C 제품에 비해 복잡하고, 사용자의 문제를 잘 파악해서 해결해야 하는 부분이 많다고 생각해요. 특히 채널톡에서는 고객 문의에 개발자나 제품팀 멤버들이 초대되어 문의를 직접 해결하기도 합니다. 그래서 이번 편은 사용자의 직접 문의(민원)를 해결하는 동사무소의 일상 컨셉이에요.

꼭 도큐먼트 제품에서 발생한 상황은 아니고, 이전에 다른 사례의 예시를 참고하기도 했으며, 적당한 각색을 통해 재구성했으니 참고해주세요!

> 이번 동사무소 편의 이전 시리즈인 "채널톡 탐정사무소" 글이 궁금하다면?
>
> - [채널톡 탐정사무소](https://channel.io/ko/blog/tech-backend-be-detective-office)

## 모든 사용자 데이터 변경에는 흔적이 남아야 한다

어느 날 굉장히 다급해 보이는 사용자 한 명이 찾아왔어요.

"제가 이것저것 만지다가 아티클(글)이 다 날아간 것 같아요 ㅠㅠ 혹시 어떻게 복구할 수 있는 방법이 없을까요? 😭"

정말 영구 삭제를 했다면 복구가 어려울텐데.. 라고 생각하며 두기는 이 때를 위해 준비한 audit log(데이터 변경 이력)을 조회해보았어요. 그런데 이 사용자에게는 아티클을 영구 삭제한 이력이 없었어요.

이상함을 느낀 두기는 사용자에게 몇 가지 물어보았고, 알고 보니 이 사용자는 글을 삭제한 것이 아니라, 그냥 메인 화면에서 노출이 안되게 숨겨놓았던 것이었어요(관련 설정값을 바꾼 이력도 있었구요). 이렇게 저렇게 하면 다시 숨김이 해제된다고 알려드렸고, 결과는 해피 엔딩!

데이터 변경 이력을 남기지 않았다면 정확하게 어떤 상황인지 파악을 하기 어려웠을거고, 그냥 영구 삭제한 글은 복원이 안돼요 😭 하고 돌려보낼 수밖에 없었을 거에요. 다른 문의가 들어왔을 때도 탐정처럼 주변 엔티티 정보를 관찰하면서 추측만 하는 게 아니라 간단하게 이력 조회로 쉽게 해결이 가능하겠죠?

- 문의가 들어왔을 때 어떤 상황에서 문제가 발생했는지 주변 맥락을 파악해야 하는데, 데이터 변경 이력은 큰 도움이 되었어요.
- **사용자는 자신이 어떤 행동을 했는지 정확하게 설명할 수 있는 경우가 드물기 때문에** 맥락을 재구성하려면 꼭 필요한 정보에요.

<img src={require("@site/static/2024-08-11-lets-make-production-ready-web-service/img1.jpg").default} width="600" />

- 문제가 사용자의 액션 때문인지, 우리 코드의 버그 때문인지 구분하는 데에도 유용한 근거로 사용할 수 있어요.

### 데이터 변경 이력 도입기

사실 데이터 변경 이력은 서비스 운영 초반부에 넣을 생각은 아니었어요. (갈 길이 급한데...)

도큐먼트는 6월 말 공식 릴리즈 전 4월에 저희 팀 내부 가이드에 먼저 릴리즈 되었어요. 그런데 릴리즈 된 지 일주일도 안 되어서 가이드 문서에 접속이 안 된다는 리포트가 들어왔어요! 😱

빠르게 확인해보니, **저희 가이드 문서 스페이스의 웹사이트 발행 상태가 OFF로 변경되어 있었어요.** 누가 테스트하거나, 데모를 보여주다가 OFF로 돌리고 까먹고 가버린 거죠. 원래 운영용 채널에서는 테스트나 데모를 하면 안 되고 이걸 위한 공간이 따로 준비되어 있지만, 항상 지켜지기를 기대하기는 어려운 일이죠.

이런 일을 다시 겪기 싫었던 두기는 결국 데이터 변경 이력 (audit log) 기능과 권한 세분화 기능을 빠르게 구현해두었어요. 다행히 코드상으로는 아래와 같이 비즈니스 로직 인터페이스를 감싸는 enhancer 패턴을 사용해서 깔끔하게 들어갈 수 있었네요!

```go
/* 인터페이스 */
type MyService interface {
  // 데이터 변경 이력과 권한 체크가 되어야 하는 오퍼레이션
  VeryImportantOperation(ctx context.Context, params VeryImportantParams) (VeryImportantResult, error)
}

/* 실제 구현 (비즈니스 로직) */
type myServiceImpl struct {
  // ...
}

func (svc *myServiceImpl) VeryImportantOperation(ctx context.Context, params VeryImportantParams) (VeryImportantResult, error) {
  // 여기에는 비즈니스 로직만 가지고 있음
}

/* Audit log 기능으로 감싼 서비스 */
type auditLogEnhancedMyService struct {
  inner MyService
  // ...
}

func (svc *auditLogEnhancedMyService) VeryImportantOperation(ctx context.Context, params VeryImportantParams) (VeryImportantResult, error) {
  // 내부 서비스 호출
  res, err := svc.inner.VeryImportantOperation(ctx, params)
  if err != nil {
    return res, err
  }

  // 여기에서 audit log 기록
  auditLogSvc.Record(ctx, "VeryImportantOperation", map[string]interface{}{
    "params": params,
    "result": res,
  })

  return res, err
}

/* ... 비슷하게 권한 체크도 처리 ... */

/* Dependency Injection 단계에서 서로 wiring 해주기 */
var Option = fx.Options(
  fx.Provide(fx.Annotate(NewMyService, fx.ResultTags(`name:"MyService.0"`))),
  fx.Provide(fx.Annotate(EnhanceWithAuditLog, fx.ParamTags(`name:"MyService.0"`))),
)
```

### 관련 사례

앞선 경우는 저희 팀에서 겪었던 사례지만, 비슷하게 팀원 간 커뮤니케이션 미스나 실수로 문제가 발생하는 경우가 많아요.

- 영구 삭제를 직접 했는데, 다시 문의해서 복원해달라고 요청하는 경우
  (안 되는 것이 원칙이지만, 가끔 가능할 때 해결해주면 굉장히 고마워함)
- 고객사의 수천 개 데이터가 갑자기 사라졌는데 범인을 몰라요. 사실 범인은 고객사의 누군가가 퇴사하면서 지우고 나간 것이었어요. 심지어 "한 번에 삭제" 기능도 아니고 수천 건을 하나하나 삭제하고 나가서 눈치채기 어려웠어요.
- 고객사의 한 팀원이 어떤 설정값을 변경했는데, 그 옆자리 팀원이 문의해서 누가 변경했는지 물어보네요. (누가 바꿨는지 알려드리고 원만히 합의 보시라고 안내) 서로 대화 좀 하세요..

## 백오피스 도구를 준비하자

또 다른 사용자가 문의를 주었어요. 이번에는 "아티클을 공개 했는데, 메인 화면에 노출이 안 된다"고 하네요. 다행히 아주아주 간단한 문의에요. 사실 이 정도는 CX팀에서 익숙해지면 해결하실 수 있는데, 아직 신규 제품이다 보니 직접 만든 저희 팀만 제품 기능에 대해 정확하게 알고 있는 것이 많아요. 그래서 메인 화면에 노출 여부를 결정하는 설정값들을 확인하려고 하는데... 어떻게 보죠? 🤔

사용자 문의가 들어오거나 버그인지 확인하는 과정은 사용자의 설정값을 살펴보고 어떤 데이터가 있는지 확인하는 것으로부터 시작해요. 이 때마다 데이터베이스에 직접 연결해서 쿼리를 날리는 것은 번거롭기도 하고, 권한이나 보안 관리가 잘 안 된다면 큰 문제가 생길 수도 있어요.

이런 상황을 위해 두기는 미리 운영 데이터베이스의 read replica를 준비해두고, 쿼리 도구인 [Redash](https://redash.io/)와 연결해두었어요. 이제 웹에 접속해서 간단하게 쿼리를 통해 원하는 데이터를 확인할 수 있고, SAML(구글 계정 로그인)로 계정과 권한 관리가 되기 때문에 걱정 없어요!

![img5](/2024-08-11-lets-make-production-ready-web-service/img5.png)

그런데 문제가 있어요. 팀에서 SQL을 짤 수 있는 사람이 백엔드 개발자(a.k.a. 바로 나)밖에 없어요. 자연스럽게 모든 고객 문의가 저로 라우팅 되어버렸어요.

이러한 상황에서 또 할 수 있는 것들이 있어요.

- 쿼리를 작성해야만 데이터를 확인할 수 있지 않도록, GUI와 검색 기능을 갖춘 백오피스 웹 클라이언트를 직접 만들어두는 것이에요. 물론 손이 많이 가는 작업이기 때문에 천천히 준비하고 있어요.
- <s>다른 팀원에게 SQL을 공부하라고 시키면 돼요.</s>

## 보고서 쓰기

도큐먼트는 신규 제품이라서 할 수 있는 것들이 많아요. 무엇을 하고 하지 않을지 고르고, 우리가 잘 하고 있는지 확인해야 하니 우리가 중요하게 생각하는 숫자를 정리하고, 매주 보고서를 작성하고 있어요. 또 보고서는 외부 홍보용으로 쓰이기도 하고, 팀에서 우리 잘하고 있다고 자랑하기 위해 쓰기도 해요.

이런 리포트 쓰는 일은 소프트웨어 개발이 아니니까 다른 사람이 해주나요? 당연히 그럴 리가 없어요. 채널 동사무소 스타트업에 다니는 개발자는 어쨌든 필요하고 내가 할 수 있는 일이면 해야 해요. 다행히 Redash를 이미 사용하고 있기 때문에 쿼리를 돌리고 결과를 시각화하는 것은 아주 쉬워요. (그냥 Redash에서 제공하는 visualization 기능을 활용하면 돼요.)

![img4](/2024-08-11-lets-make-production-ready-web-service/img4.png)

금방 다채로운 대시보드 리포트가 완성되었어요!

다른 팀의 요청으로 데이터 추출이 필요한 경우에도 CSV export 기능을 유용하게 쓸 수 있어요. 쿼리 결과를 다른 사람들이 Excel이나 구글 스프레드시트에서 확인할 수 있게 하기 위해 코드 몇 줄 더 작성할 필요도 없어요.

서비스 개발과 비즈니스 로직 구현은 내가 가장 익숙한 환경에서 제일 잘 사용할 수 있는 프레임워크와 도구를 사용하기 때문에 빠르게 무언가를 만들어내는 것은 능숙해지면 어렵지 않습니다. 오히려 사용자의 문의 확인과 해결, 서비스 운영에 필요한 지표 확인, 다른 팀과의 소통에서 도구가 익숙하지 않아 시간을 많이 사용하는 경우가 많다는 것을 느꼈어요.

## 데이터베이스 백업과 복구

이건 다행히 실제 운영단계는 아니고 개발 스테이징 서버의 에피소드에요.

같이 도큐먼트를 개발하는 클라이언트 팀원이 갑자기 개발 서버에 테스트 중이던 데이터가 다 사라졌다고 멘션을 줬어요! 화들짝 놀란 두기는 빠르게 확인해봤는데, 진짜 데이터가 날아갔고 심지어 그 팀원이 보던 데이터 뿐만이 아니라 **전체 데이터베이스가 날아간 것이었어요!** 😱😱

<img src={require("@site/static/2024-08-11-lets-make-production-ready-web-service/img2.png").default} width="400" />

나중에 쿼리 실행 로그를 보고 원인은 찾으면 되고, 그 전에 데이터베이스 복구를 해야겠죠. 다행히 저희 데이터베이스는 Amazon RDS 상에서 운영되고 있고, 스테이징 환경에서는 매일 자동으로 PITR 백업이 기록돼요. PITR 백업을 그대로 쓸 수는 없었어요(그 인스턴스의 모든 데이터베이스가 PITR 시점으로 리셋되는건데, 저희 데이터베이스만 날아간 것이었거든요). 하지만 PITR로부터 새 인스턴스를 띄운 후 pg_dump로 데이터를 덤프 뜨고, 원래 인스턴스에 데이터를 밀어넣으니 복구 완료!

사실 원인은 개발 환경에 붙어서 테스트 코드를 돌리다가 통합 테스트 코드의 truncate (`TRUNCATE TABLE {table_name} CASCADE`) 로직이 스테이징 데이터베이스에서 돌아간 것이었어요. 통합 테스트는 매번 테스트 데이터베이스를 초기화하고 실행하기 때문이죠. 코드상으로 실수가 발생할 수 있어보여 통합 테스트는 로컬 호스트에 대해서만 돌릴 수 있도록 방어 로직을 추가했어요.

<figure>
  <img src={require("@site/static/2024-08-11-lets-make-production-ready-web-service/img3.png").default} width="600" />
  <figcaption>(대문짝한 경고 문구)</figcaption>
</figure>

- PITR로 복구가 가능한 건 머리로 알고 있었는데, 직접 복구하는 과정을 경험해보았어요! (개발자 업적 달성 🎉)
- 실제 서비스였다면 PITR만으로는 부분적인 데이터 손실이 있어 추가적인 작업도 진행해야 할 거에요. 그리고 다른 마이크로서비스와의 정합성 오류도 체크 해야겠죠.
- 로컬 데이터베이스를 매번 초기화하면서 통합 테스트를 실행하는 것은 다른 문제도 있어요. 테스트 케이스 간 간섭이 일어나면 안 되기 때문에 테스트 케이스를 동시에 하나만 돌릴 수 있어 테스트 실행 속도가 느립니다. 테스트를 많이 작성할수록 점점 불편해지고 있어 대첵이 필요한데, PostgreSQL과 호환되는 인메모리 데이터베이스를 활용하는 편이 좋을 것 같네요!

## Admin

18. 개발자의 업무 시간을 잡아먹는 것은 Administration

- 토이프로젝트만 해 본 뉴비에게 실제 서비스 운영 경험을 꼭 추천하는 이유입니다.

- 많은 서비스에서 코어 비즈니스 로직은 "사실" 그렇게 까다로운 부분은 아닙니다.

  - 제일 중요하기 때문에 제일 잘 만들어두는 부분

  - 가장 좋은 구조로 설계해두고 깔끔

  - 정작 시간에 쫓겨 정밀하지 못한 코드나, 우아하지 못한 구조로 추가하게 되는 부분은 긴급한 버그 픽스나 admin 작업

- 버그로부터 생긴 데이터 부정합 고치기, 고객 요청에 따른 데이터 확인 또는 수정, 신규 기능 추가에 따른 마이그레이션이 개발자의 시간을 잡아먹습니다.

  - 우리 팀의 경우 (B2B SaaS 도메인) 고객 요청이 많고 사용자 문의로 목소리를 직접 듣게 됨

  - 단순 확인 문의부터, 버그가 발생한 상황인지 맥락 확인, 데이터 옮겨주세요, 데이터 부어주세요, 등등

- 중요한 고객의 요청 하나를 해결하는데 일주일 중 3일을 쓰면 안 됨

- 그렇다고 사용자 문의에 귀를 닫게 되면 1차 피드백을 얻을 창구가 사라지고 점점 뇌피셜로 제품을 만듬

- 이 부분을 적은 노력으로 해결해야 내 시간을 절약해서 사용자에게 필요한 기능을 개발하는 데 쓸 수 있습니다.

### Admin API

19. 엔티티에 대한 읽기와 쓰기 API는 항상 만들어둡니다.

- 반복 작업이고 패턴이 있기 때문에, 프레임워크나 code generation을 사용해도 좋을 것 같습니다.

- 이 부분에서 GitHub Copilot에게 많은 도움을 받고 있습니다. 함수 이름만 잘 작성해도 대부분의 코드를 패턴에 맞게 만들어줌

20. 반복적으로 들어오는 요청 해결 위주로

- 운영 데이터베이스에 update 쿼리를 자주 날리고 있다면 그 작업에 대한 admin API가 필요하다는 신호입니다.

- 다시 한번 개발자 머피의 법칙 (https://techblog.woowahan.com/2645/) 글 추천

- Admin API 호출도 사용자 요청과 마찬가지로 audit log가 남아야 합니다.

21. SDK

- 서버사이드에서 Admin API를 만들었으면, 그걸 클라이언트 사이드에서 코드로 호출할 수 있는 SDK도 준비해두는 것이 유용했습니다.

- 클라이언트 사이드 코드도 생성할 수 있는 도구도 많이 있습니다만 (gRPC같은걸 쓴다면 특히) 이런 걸 아직 사용하고 있지는 않습니다.

  역시 GitHub Copilot의 도움을 많이 받고 있음

- 이전 프로젝트에서 복잡한 작업을 셸스크립트로 만들었지만, 셸스크립트에 능숙하지 않아 작업이 턱턱 막히고 비즈니스 로직을 활용하지 못하는 점이 아쉬움이었습니다.

- 스크립트가 메인 프로젝트와 동일한 repository에서 코드와 비즈니스 로직을 공유할 때 다양한 작업을 처리할 수 있구나 생각했습니다. (메인 애플리케이션과 스크립트를 모노레포로 구성)

### 재사용 가능한 스크립트

22. 결과적으로, Admin API와 모노레포 구조를 통해 복잡한 로직을 담은 스크립트를 30분 내에 뚝딱 작성할 수 있게 되었습니다.

- 데이터 스캔하면서 통계값을 뽑기

- 데이터 정합성 맞추는 마이그레이션 스크립트

- 외부 데이터를 import 혹은 export

- Secondary database로의 전체 혹은 부분 데이터 동기화

23. 스크립트 작성하고 돌리며 했던 실수

- 원래 운영 환경에서 로그가 warn 이상 레벨이었는데, 스크립트에서 출력하는 로그는 info레벨이었기 때문에 로그를 못 보고 스크립트가 끝날 때까지 기다렸던 적이 있습니다.

  - 사실 이것 외에도 운영 환경의 "서버"와 "스크립트"는 살짝 configuration이 다르기 때문에 환경을 구분하는 것이 맞는 선택이었음

- 마찬가지로 스크립트에서 발생한 에러가 이슈 추적 도구(sentry와 datadog 등)에 운영 서버와 동등하게 추적되어 혼란을 주었던 문제

- 중간에 에러가 발생했을 때 에러 로그를 출력하긴 했는데 어떤 데이터에서 에러가 발생했는지를 같이 출력 안해서 찾는데 고생

24. 로그

- 스크립트에서 progress 로그를 print하지 않으면, 스크립트를 실행하는 순간..

  - 돌고 있는건지 어딘가에서 막혀있는건지.. 구별이 안됨

- 로그에 정보를 되도록 많이 담아야 잘못 돌았을 때 실수를 커버할 수 있습니다.

- Dry run 옵션

  - 운영환경 데이터에 개발환경과 다른 문제가 있을 수도 있음

  - 단순히 개발환경에서 충분히 많은 케이스를 테스트를 못했을 수도 있고

  - 데이터 정합성 조건이 변했다던가, 미처 마이그레이션 못한 옛날 데이터라던가, 등등

  - Dry run 옵션을 두고 잘 구현하면 안전하게 테스트 할 수 있음

- Documentation과 스크립트 실행 옵션에 대한 설명을 상세히 달아두면, 내가 휴가 갔을 때도 다른 팀원이 돌릴 수 있는 스크립트가 됩니다.

25. 부수효과

- 다양한 스크립트를 보유하고 있어, 팀에서 기능 QA할 때 쉽게 테스트 환경을 세팅할 수 있게 되었습니다.

- 특히 최근에 릴리즈 한 AI 기반 상담 응대 (RAG) 기능에서 잘 써먹음

### Administration: 정리

26. 스노우볼 굴리기

- 반복적인 작업 처리를 위해 Admin API를 만들어둠

  -> 복잡한 요청들을 거절하지 않고 API 요청 몇 개로 해결

  -> 다시 반복되는 요청 패턴을 Admin SDK와 스크립트로 만들어둠

  -> 스크립트가 여러 개 생기니, 스크립트 템플릿도 만들고 스크립트를 작성하고 돌리기가 쉬워짐

- 패턴화와 내 업무 경험 개선의 반복

- 복잡한 문의 해결을 요구하는 엔터프라이즈 레벨 고객 퀘스트도 깰 수 있게 되어 서비스에 락인 시키고, 서비스 지표에도 도움이 됨

- 일주일에 이러한 요청 두세 개 처리하면서 기능 개발 스케줄에도 문제가 없었다! (휴)

## 국가적 재난상황

개발자는 버그를 만들고 버그를 고쳐요.

누구나 실수를 할 수 있고 작은 버그로 정리되는 해프닝도 있지만 서비스 전체가 먹통이 되는 큰 장애도 발생하는 법이에요. 하지만 모든 실수를 개발과 테스트 단계에서 잡고 갈 수는 없습니다. 그러려면 코드 리뷰에 시간을 쓰고, QA 시나리오 작성하고 며칠 테스트 하고, 기존 기능에 문제가 없는지 regression 테스트도 계속 하면서 새로운 기능을 릴리즈 해야 해요. 새롭게 만들어지고 있는 제품을 개발하면서 이렇게 방향성을 잡는 것은 맞지 않아요.

다만 저는 실수해도 빠르게 바로잡을 수 있는 문화를 가지면 좋겠어요.

1. **실수 한 것을 최대한 빨리 인지.** (기술적으로는 알람과 로그 시스템, 팀에서는 핫라인과 온콜 담당자 지정)
2. **고객에게 장애 발생을 잘 전파.** 저희 팀에서는 [Status](https://status.channel.io) 페이지를 운영하고 있어요. 그리고 CX팀에서 여러 사용자 커뮤니티에 참여하고 있는데, 제품팀에서 장애가 발생했다고 전달받으면 고객에게 전파하기도 해요. 먼저 제보를 받기도 하구요.
3. **이유와 복구 상황 설명.** 장애를 해결하는 개발자 본인은 원인 파악과 대처에 바빠서 다른 사람들에게 설명할 시간까지는 없는 경우가 많아요. 팀원이 같이 붙어서 상황을 중계해주고 다른 팀이나 고객 커뮤니티에 연결해주는 역할이 필요해요.
4. **실수를 잘 수습하기.** 데이터 정합성이 깨졌으면 다시 맞추고, 손실되었으면 어떤게 얼마나 손실되었는지 파악하고, 사용자에게 보상이 필요하면 영향받은 고객 목록과 보상 방안을 고민하는 것도 해야해요. 실수를 수습하려면 할 일이 많아요. 개발자가 모두 중요한 역할을 해줘야 해요.

**일단 1번이 제일 중요한 것 같아요.** 같은 원인과 현상의 장애라도 5분만에 상황 종료되느냐, 1시간이 넘어가느냐에 따라 가벼운 해프닝으로 끝날 일이 수많은 사람들의 민원과 보상을 해줘야 하는 문제로 바뀔 수도 있네요.

### 사고일지

**릴리즈 이후 총 3번 장애가 있었습니다.** 두 번째 incident를 겪은 후 사고 리포트를 쓰기 시작했는데, 이 글을 쓰는 데에도 큰 도움이 되었어요. 리포트에는 장애 당일 대응한 내용을 기록해두고, 원인을 정리한 후 단기적으로 고쳐져야 하는 부분을 까먹지 않기 위해서, 그리고 중장기적으로 고쳐져야 할 점을 적어두었어요.

추가로 [개발자 머피의 법칙](https://techblog.woowahan.com/2645/) 글을 추천하고 싶은데, 사고를 겪는 과정에서 이 글 내용 생각이 계속 났기 때문입니다. 신중해야 할 곳에서 충분히 생각 안 하고 만들었을 때 어떻게 약한 부분이 터지는지 재미있는 에피소드로 설명해주는 글이었어요.

#### 사고일지 I

이 문제는 **사용자의 입력을 충분히 검증하지 않아서 발생한 문제**에요. 이 장애를 겪고 난 뒤로 기획적으로 validation이 없는 입력 필드에도 _무조건_ 최대 길이를 정해두어야 한다고 생각하게 되었어요.

도큐먼트 기능이 출시된 지 3주밖에 지나지 않았던 때였는데, 신규 기능이었기 때문에 아주 작고 귀여운 서버를 할당해두었어요. RAM 할당이 500MiB밖에 되지 않았거든요. 그런데 사용자가 너무 큰 입력을 보내고 저장에 성공해버리면서, **그 entity를 조회할 때마다 메모리에 올려두고 있어야 해서 서버 프로세스에서 OOM이 발생했어요**. 프로세스 하나 정도는 종료될 수 없겠지만, 그 사용자가 어 왜 안되지? 하면서 계속 요청을 보낼때마다 프로세스가 하나하나씩 암살당하면서 모든 프로세스가 unhealthy 상태로...

수습은 일단 리소스 할당을 늘리면서 5분만에 상황은 끝났지만, 뒤처리가 약간 고생이었습니다. 너무 큰 입력이 저장되어버린 엔티티를 정상화 해야겠는데, 또 사용자의 데이터니까 손실이 되지 않게 처리해야 했네요. 또 나중에 확인해보니 정상 크기가 아닌 엔티티가 100개 넘게 있어서 하나하나 스크립트 돌려가며 정리했어요.

#### 사고일지 II

이번에는 서버 프로세스 자체는 healthy 였어요. 그래서 healthcheck 요청에는 계속 응답 하니까 알람이 안 울렸어요.

그런데 도큐먼트로 만든 웹사이트 접속이 안 된다고 제보가 들어온거에요! 😱 확인해보니 프로세스 중 하나에서 데이터베이스로의 연결이 모두 timeout 나면서 사용자 요청이 처리가 안 되고 있었어요. 그 프로세스를 종료하고 새로 띄우니 문제가 해결되었습니다.

알람이 울리지 않아서 문제가 생긴 후 30분이 지나서야 인지를 했고, 그 후 5분만에 복구 했어요. 하지만 30분이나 먹통이었던 것이 아쉬워서 다음에는 healthcheck에서 애플리케이션이 의존하는 다른 외부 서비스(RDS, Redis, 메시지 큐, 등등)의 health도 체크하도록 해야겠다고 생각했어요.

#### 사고일지 III

마지막 사건은 코드 실수로 데이터 처리 작업 일부가 손실되는 문제였어요. 비동기 처리로 돌린 작업이 실행 도중 취소될 수 있는 문제였는데, 사용자의 요청을 직접 처리하는 데에는 문제가 없었기 때문에 사용자로부터나 내부 제보가 있지 않아서 늦게 발견했어요. 다행히 secondary database에서 조회하는 쿼리 결과가 이상하다는 제보의 원인을 파보다 보니 코드 실수가 배포된 지 하루가 지나기 전에 문제를 찾을 수 있었죠.

이제 정합성을 맞춰야 하는데요... 문제가 있는 코드가 배포되었던 시간 동안 동기화가 깨진 데이터를 찾고, 다시 손실된 작업분을 보충해주는 스크립트를 수동으로 돌렸어요. (다른 팀에 전달해주는 데이터도 다시 replay 해주어야 했구요) 서비스 출시 초기라서 데이터 수가 수백개 밖에(?) 안 되엇기 때문에 괜찮았지만, 더 늦게 발견했거나 데이터 수가 많았다면 훨씬 손이 많이 가는 작업이었을 거에요.

장기적으로는 Apache Kafka나 Amazon Kinesis Data Stream처럼 이벤트를 replay할 수 있는 스트림 컴포넌트를 쓰는것이 좋을거에요. 하지만 역시 문제는 이런 것들을 언제 도입하는 것이 적절하냐의 문제입니다. (닭잡칼 🐓 vs 소잡칼 🐄 의 딜레마)

## 마무리

TBD
